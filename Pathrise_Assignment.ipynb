{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pathrise Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AcnbuYH5BfkJ4ndkucuFabtea6P1YAhP",
      "authorship_tag": "ABX9TyPN/JRktXpZO2RfLUm3eA8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a764fa0266d496694ef8862ff62a85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35042cee6d654488b722eb2bb95ace51",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6c3711219cb4147875ca0343ef1b329"
          }
        },
        "35042cee6d654488b722eb2bb95ace51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6c3711219cb4147875ca0343ef1b329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bab8357589254fe480401e56b10f830b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_b4a7e69161a946b784bd859bb803cd94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fb8d46d519248f5b28b45f1001cb20d"
          }
        },
        "b4a7e69161a946b784bd859bb803cd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fb8d46d519248f5b28b45f1001cb20d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adee68c150bf489c889545687cbbc579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab1ebe96f6734ea8ac48d8f733a5e0f4",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 170,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d1fbc4553ff4804b45074db0e1b49fa"
          }
        },
        "ab1ebe96f6734ea8ac48d8f733a5e0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d1fbc4553ff4804b45074db0e1b49fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parasgulati8/Data-Analysis/blob/master/Pathrise_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6guCjLx5E6n0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a0820165-e0a2-4a05-ba41-513def4375c3"
      },
      "source": [
        "cd drive/'My Drive'/'Colab Notebooks'/'Pathrise Assignment'/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/Pathrise Assignment/'\n",
            "/content/drive/My Drive/Colab Notebooks/Pathrise Assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMrpdaxktUUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6lAdlyDM7GV",
        "colab_type": "text"
      },
      "source": [
        "# 1. Important Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgVeTJGPFZHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from sklearn.metrics import classification_report, r2_score\n",
        "from functools import reduce\n",
        "from scipy.stats import norm\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "from functools import reduce\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.decomposition import KernelPCA, PCA\n",
        "from sklearn.model_selection import GridSearchCV, KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfhLDkAQNCJj",
        "colab_type": "text"
      },
      "source": [
        "# 2. Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghdsmTUNFeZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_excel('data_Pathrise.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwka-FutFp3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "c99413e2-aed5-40d8-d5ac-cc24199fa2cd"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pathrise_status</th>\n",
              "      <th>primary_track</th>\n",
              "      <th>cohort_tag</th>\n",
              "      <th>program_duration_days</th>\n",
              "      <th>placed</th>\n",
              "      <th>employment_status</th>\n",
              "      <th>highest_level_of_education</th>\n",
              "      <th>length_of_job_search</th>\n",
              "      <th>biggest_challenge_in_search</th>\n",
              "      <th>professional_experience</th>\n",
              "      <th>work_authorization_status</th>\n",
              "      <th>number_of_interviews</th>\n",
              "      <th>number_of_applications</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Active</td>\n",
              "      <td>SWE</td>\n",
              "      <td>OCT19A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Unemployed</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>3-5 months</td>\n",
              "      <td>Hearing back on my applications</td>\n",
              "      <td>3-4 years</td>\n",
              "      <td>Canada Citizen</td>\n",
              "      <td>2.0</td>\n",
              "      <td>900</td>\n",
              "      <td>Male</td>\n",
              "      <td>Non-Hispanic White or Euro-American</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Active</td>\n",
              "      <td>PSO</td>\n",
              "      <td>JAN20A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Unemployed</td>\n",
              "      <td>Some College, No Degree</td>\n",
              "      <td>3-5 months</td>\n",
              "      <td>Getting past final round interviews</td>\n",
              "      <td>1-2 years</td>\n",
              "      <td>Citizen</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Non-Hispanic White or Euro-American</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Closed Lost</td>\n",
              "      <td>Design</td>\n",
              "      <td>AUG19B</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Employed Part-Time</td>\n",
              "      <td>Master's Degree</td>\n",
              "      <td>Less than one month</td>\n",
              "      <td>Figuring out which jobs to apply for</td>\n",
              "      <td>Less than one year</td>\n",
              "      <td>Citizen</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>East Asian or Asian American</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Closed Lost</td>\n",
              "      <td>PSO</td>\n",
              "      <td>AUG19B</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contractor</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Less than one month</td>\n",
              "      <td>Getting past final round interviews</td>\n",
              "      <td>Less than one year</td>\n",
              "      <td>Citizen</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25</td>\n",
              "      <td>Male</td>\n",
              "      <td>Decline to Self Identify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Placed</td>\n",
              "      <td>SWE</td>\n",
              "      <td>AUG19A</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Unemployed</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>1-2 months</td>\n",
              "      <td>Hearing back on my applications</td>\n",
              "      <td>1-2 years</td>\n",
              "      <td>F1 Visa/OPT</td>\n",
              "      <td>10.0</td>\n",
              "      <td>100</td>\n",
              "      <td>Male</td>\n",
              "      <td>East Asian or Asian American</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id pathrise_status  ... gender                                 race\n",
              "0   1          Active  ...   Male  Non-Hispanic White or Euro-American\n",
              "1   2          Active  ...   Male  Non-Hispanic White or Euro-American\n",
              "2   3     Closed Lost  ...   Male         East Asian or Asian American\n",
              "3   4     Closed Lost  ...   Male             Decline to Self Identify\n",
              "4   5          Placed  ...   Male         East Asian or Asian American\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SXbKMk9NIpc",
        "colab_type": "text"
      },
      "source": [
        "# 3. Data Cleaning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Wdj-7xlbHk",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Dealing with NaN values of program_duration_days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdh1C4ZvGBh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "60df2960-35c2-469a-a4a9-149b39131b11"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                               0\n",
              "pathrise_status                  0\n",
              "primary_track                    0\n",
              "cohort_tag                       8\n",
              "program_duration_days          616\n",
              "placed                           0\n",
              "employment_status              229\n",
              "highest_level_of_education      58\n",
              "length_of_job_search            74\n",
              "biggest_challenge_in_search     24\n",
              "professional_experience        222\n",
              "work_authorization_status      284\n",
              "number_of_interviews           218\n",
              "number_of_applications           0\n",
              "gender                         492\n",
              "race                            18\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jhvOt2VMRux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fillna_program_duration(data1):\n",
        "  '''\n",
        "  Fill NaN values in program_duration_days with the median value in same cohort_tag\n",
        "\n",
        "  input: data1 : pandas DataFrame read from the csv file\n",
        "  returns: data2 : pandas DataFrame after filling the NaN values in program_duration_days\n",
        "  '''\n",
        "  data2 = pd.DataFrame(columns= data1.columns)\n",
        "  for i in data1.cohort_tag.unique():\n",
        "    med = data1[data1.cohort_tag == i]['program_duration_days'].median()\n",
        "    temp = data1[data1.cohort_tag == i].fillna(value = {'program_duration_days':med})\n",
        "    \n",
        "    data2 = pd.concat([data2, temp])\n",
        "\n",
        "  return data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9MhzmCl2-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = fillna_program_duration(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC21sNk82YAx",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Converting the categorcal value to numerical values. \n",
        "\n",
        "<h3>It helps the model to establish relationships between feature in a better way\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyN4qgviGGy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(data):\n",
        "  '''\n",
        "  modifies the professional_experience, length_of_job_search and highest_level_of_education columns of the data.\n",
        "\n",
        "  Changes in professional_experience are as follows: '1-2 years':2, '3-4 years':3, 'Less than one year':1, '5+ years':4, np.nan:0\n",
        "  Changes in length_of_job_search are as follows: 'Less than one month':1, '1-2 months':2, '3-5 months':3,\n",
        "        '6 months to a year':4, 'Over a year':5, np.nan:0\n",
        "  Changes in highest_level_of_education are as follows: \"Bachelor's Degree\":3, \"Master's Degree\":4, 'Some College, No Degree':0,\n",
        "        'Some High School':1, 'Doctorate or Professional Degree':5,\n",
        "        'High School Graduate':2, np.nan:0, 'GED or equivalent':2\n",
        "        \n",
        "  '''\n",
        "  placed = data.copy()\n",
        "  placed.professional_experience.replace({'1-2 years':2, '3-4 years':3, 'Less than one year':1, '5+ years':4, np.nan:0}, inplace=True)\n",
        "  placed.length_of_job_search.replace({'Less than one month':1, '1-2 months':2, '3-5 months':3,\n",
        "        '6 months to a year':4, 'Over a year':5, np.nan:0}, inplace = True)\n",
        "\n",
        "  placed.highest_level_of_education.replace({\"Bachelor's Degree\":3, \"Master's Degree\":4, 'Some College, No Degree':0,\n",
        "        'Some High School':1, 'Doctorate or Professional Degree':5,\n",
        "        'High School Graduate':2, np.nan:0, 'GED or equivalent':2}, inplace =True)\n",
        "  placed = placed.drop(columns=['id', 'cohort_tag', 'race', 'gender'])\n",
        "  placed1 =  pd.get_dummies(placed, columns=['primary_track', 'employment_status ', 'biggest_challenge_in_search', 'work_authorization_status', 'pathrise_status' ], drop_first=True).fillna(0)\n",
        "\n",
        "  return placed1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJy_5bTk6Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = clean_data(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgcHyeqcmYxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "ddb1e4f5-6889-4a78-c440-6dc319a46a96"
      },
      "source": [
        "data1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>program_duration_days</th>\n",
              "      <th>placed</th>\n",
              "      <th>highest_level_of_education</th>\n",
              "      <th>length_of_job_search</th>\n",
              "      <th>professional_experience</th>\n",
              "      <th>number_of_interviews</th>\n",
              "      <th>number_of_applications</th>\n",
              "      <th>primary_track_Design</th>\n",
              "      <th>primary_track_Marketing</th>\n",
              "      <th>primary_track_PSO</th>\n",
              "      <th>primary_track_SWE</th>\n",
              "      <th>primary_track_Web</th>\n",
              "      <th>employment_status _Employed Full-Time</th>\n",
              "      <th>employment_status _Employed Part-Time</th>\n",
              "      <th>employment_status _Student</th>\n",
              "      <th>employment_status _Unemployed</th>\n",
              "      <th>biggest_challenge_in_search_Figuring out which jobs to apply for</th>\n",
              "      <th>biggest_challenge_in_search_Getting past final round interviews</th>\n",
              "      <th>biggest_challenge_in_search_Getting past mid-stage interviews</th>\n",
              "      <th>biggest_challenge_in_search_Getting past phone screens</th>\n",
              "      <th>biggest_challenge_in_search_Hearing back on my applications</th>\n",
              "      <th>biggest_challenge_in_search_Lack of relevant experience</th>\n",
              "      <th>biggest_challenge_in_search_Resume gap</th>\n",
              "      <th>biggest_challenge_in_search_Technical interviewing</th>\n",
              "      <th>biggest_challenge_in_search_Technical skills</th>\n",
              "      <th>work_authorization_status_Citizen</th>\n",
              "      <th>work_authorization_status_F1 Visa/CPT</th>\n",
              "      <th>work_authorization_status_F1 Visa/OPT</th>\n",
              "      <th>work_authorization_status_Green Card</th>\n",
              "      <th>work_authorization_status_H1B</th>\n",
              "      <th>work_authorization_status_Not Authorized</th>\n",
              "      <th>work_authorization_status_Other</th>\n",
              "      <th>work_authorization_status_STEM OPT</th>\n",
              "      <th>pathrise_status_Break</th>\n",
              "      <th>pathrise_status_Closed Lost</th>\n",
              "      <th>pathrise_status_Deferred</th>\n",
              "      <th>pathrise_status_MIA</th>\n",
              "      <th>pathrise_status_Placed</th>\n",
              "      <th>pathrise_status_Withdrawn</th>\n",
              "      <th>pathrise_status_Withdrawn (Failed)</th>\n",
              "      <th>pathrise_status_Withdrawn (Trial)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>900</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>52.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>55.5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     program_duration_days  ...  pathrise_status_Withdrawn (Trial)\n",
              "0                     55.5  ...                                  0\n",
              "12                    12.0  ...                                  1\n",
              "13                    52.0  ...                                  0\n",
              "56                    26.0  ...                                  0\n",
              "223                   55.5  ...                                  0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpcxpsNJjAB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enrolled_unplaced = data1[(data1.placed == 0) & (data.pathrise_status == 'Active')]\n",
        "ultimately_unplaced = data1[(data.placed == 0)  & (data.pathrise_status != 'Active')]\n",
        "placed = data1[data.placed == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUN_3EzmNYii",
        "colab_type": "text"
      },
      "source": [
        "# 4. Data Wrangling and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNm4ONDPjzgd",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. Distribution of Pathrise Fellows in Different Tracks and Status  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbmVK7htyPK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "track_counts = reduce(lambda x,y : pd.merge(x, y, how = 'left', left_index=True, right_index=True), [data[(data.placed == 0) & (data.pathrise_status == 'Active')].primary_track.value_counts(), \n",
        "                                                                                                      data[(data.placed == 0)  & (data.pathrise_status != 'Active')].primary_track.value_counts(), \n",
        "                                                                                                     data[data.placed == 1].primary_track.value_counts()])\n",
        "\n",
        "track_counts =track_counts.rename(columns = {'primary_track_x': 'enrolled_unplaced', 'primary_track_y':'ultimately_unplaced', 'primary_track': 'placed'})\n",
        "track_counts.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxVVzNx-spZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "65fb5e30-285a-42a2-8a7d-c0023713d94d"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "# Values of each group\n",
        "bars1 = track_counts.placed\n",
        "bars2 = track_counts.enrolled_unplaced\n",
        "bars3 = track_counts.ultimately_unplaced\n",
        " \n",
        "# Heights of bars1 + bars2\n",
        "bars = np.add(bars1, bars2).tolist()\n",
        " \n",
        "# The position of the bars on the x-axis\n",
        "r = range(len(track_counts))\n",
        " \n",
        "# Names of group and bar width\n",
        "names = track_counts.index\n",
        "barWidth = 1\n",
        " \n",
        "# Create brown bars\n",
        "plt.bar(r, bars1, color='#7f6d5f', edgecolor='white', width=barWidth, label = 'Placed')\n",
        "# Create green bars (middle), on top of the firs ones\n",
        "plt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white', width=barWidth, label = 'enrolled_unplaced')\n",
        "# Create green bars (top)\n",
        "plt.bar(r, bars3, bottom=bars, color='b', edgecolor='white', width=barWidth, label= 'ultimately_unplaced')\n",
        "\n",
        "# Custom X axis\n",
        "plt.xticks(r, names, fontweight='bold')\n",
        "plt.xlabel(\"group\")\n",
        "\n",
        "plt.legend() \n",
        "# Show graphic\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsOlpDsQI8E7",
        "colab_type": "text"
      },
      "source": [
        "**<h1>Points to note:</h1>**\n",
        "\n",
        "1) Most of the placed fellows belong to SWE track. \n",
        "\n",
        "2) Only one fellow placed from Web and Marketing tracks\n",
        "\n",
        "3) For PSO track, most of the fellows found their job in less than a month\n",
        "\n",
        "4) For SWE, Data, and Design tracks, most of the fellows found their job in 1-2 month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwnsNe49Jg62",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Plotting Number of Applications vs Number of Interviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gts8U0OWk3sM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "3f02a0ed-be4c-4b1b-c9c7-5eff3965125f"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.scatterplot(x = 'number_of_applications', y = 'number_of_interviews' , hue = 'pathrise_status', data=pd.concat([data[(data.placed == 0) & (data.pathrise_status == 'Active')], \n",
        "                                                                                                      data[(data.placed == 0)  & (data.pathrise_status != 'Active')], \n",
        "                                                                                                     data[data.placed == 1]]),\n",
        "                 size='professional_experience')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe3532b9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q63zISMES2B",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Analysing Distribution of Placed Students"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou9OBtg5ESSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian(placed1):\n",
        "  '''\n",
        "  Calculates the multivariate gaussian probability of input dataframe across all features\n",
        "\n",
        "  input: pandas Dataframe\n",
        "  returns: list of probabilities for all sample in sorted order\n",
        "  '''\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  x = placed1.values\n",
        "  x_scaled = scaler.fit_transform(x)\n",
        "  placed1 = pd.DataFrame(x_scaled)\n",
        "\n",
        "  placed1_mean = placed1.describe().iloc[1, :]\n",
        "  placed1_std = placed1.describe().iloc[2,:]\n",
        "  p1 = []\n",
        "  for i in range(len(placed1_mean)):\n",
        "    p1.append(norm.pdf( placed1.iloc[:,i].values, placed1_mean[i], placed1_std[i]))\n",
        "  p1 = np.array(p1).reshape((-1,len(p1)))\n",
        "  p1 = pd.DataFrame(p1).dropna().values\n",
        "  p1 = np.product(p1, axis = 1)\n",
        "  return sorted(p1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebaiEGqoP-9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "2a74630a-26f8-4b58-a9b8-5d9767662942"
      },
      "source": [
        "p1 = gaussian(placed)\n",
        "p2 = gaussian(ultimately_unplaced)\n",
        "p3 = gaussian(enrolled_unplaced)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1740: RuntimeWarning: invalid value encountered in true_divide\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  return (a <= x) & (x <= b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in less_equal\n",
            "  return (a <= x) & (x <= b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1740: RuntimeWarning: invalid value encountered in true_divide\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  return (a <= x) & (x <= b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in less_equal\n",
            "  return (a <= x) & (x <= b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1740: RuntimeWarning: invalid value encountered in true_divide\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  return (a <= x) & (x <= b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in less_equal\n",
            "  return (a <= x) & (x <= b)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QYQ7xlMRKw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "172b6674-30f7-4a8e-c664-6e73162b8a77"
      },
      "source": [
        "plt.figure(figsize=(35,3))\n",
        "\n",
        "plt.scatter(p1, [0]*len(p1), label = 'Placed', marker='o', norm = True)\n",
        "plt.scatter(p2, [0]*len(p2), label = 'Inactive Unplaced', marker='.', norm = True)\n",
        "plt.scatter(p3, [0]*len(p3), label = 'Active Unplaced', marker='x', norm=True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2520x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOpL55MGvjK",
        "colab_type": "text"
      },
      "source": [
        "<h2>This Plot shows that the avtive unplaced are close to Placed in terms of probability and in some cases overlapping with placed. Ultimately unplaced students are those who either withdrawn from the program and failed to get placed while. </h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ-oDciVGR3s",
        "colab_type": "text"
      },
      "source": [
        "# 5. Predicting if the student will utimately be placed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cmbLbMjoK6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity_placed = cosine_similarity(placed.values,  placed.values).mean(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx-Drx0CDsy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b1a5493a-03da-436e-af1f-8295af912e7c"
      },
      "source": [
        "threshold = 0.7\n",
        "print((similarity_placed > threshold).sum(), (similarity_placed <= threshold).sum())\n",
        "print('accuracy = ', (similarity_placed > threshold).sum()/ len(similarity_placed))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "899 55\n",
            "accuracy =  0.9423480083857443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwZhJ4xgp6p6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4f64e5c1-9eae-4eed-873b-e91a83cab0c4"
      },
      "source": [
        "similarity_enrolled_unplaced = cosine_similarity(enrolled_unplaced.values, placed.values).mean(axis = 1)\n",
        "print((similarity_enrolled_unplaced > threshold).sum(), (similarity_enrolled_unplaced <= threshold).sum())\n",
        "print('Prediction = ', (similarity_enrolled_unplaced > threshold).sum()/ len(similarity_enrolled_unplaced))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "443 87\n",
            "Prediction =  0.8358490566037736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG9_7FXLtzqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "963c29a8-854d-4661-c53a-0479a289ff8e"
      },
      "source": [
        "enrolled_unplaced['student_will_get_placed'] = similarity_enrolled_unplaced > threshold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foqAlMk05hWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pd.merge(data[['id']], enrolled_unplaced[['student_will_get_placed']], left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiMWNloF6uKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "18f1f67d-311d-4e4b-83cf-7bf868895d32"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>student_will_get_placed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>224</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>392</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>394</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>465</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>2020</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>2228</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2409</th>\n",
              "      <td>2410</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1721</th>\n",
              "      <td>1722</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2147</th>\n",
              "      <td>2148</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>530 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  student_will_get_placed\n",
              "0        1                    False\n",
              "223    224                     True\n",
              "391    392                     True\n",
              "393    394                    False\n",
              "464    465                    False\n",
              "...    ...                      ...\n",
              "2019  2020                     True\n",
              "2227  2228                     True\n",
              "2409  2410                     True\n",
              "1721  1722                     True\n",
              "2147  2148                     True\n",
              "\n",
              "[530 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_CmrrD4GIhM",
        "colab_type": "text"
      },
      "source": [
        "# 6.Predicting the duration it will take to get placed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeTtWiU0G9cE",
        "colab_type": "text"
      },
      "source": [
        "## 6.1. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLTjSg4XsBTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(placed.drop(columns=['program_duration_days']), placed.program_duration_days, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbSWSgq4uF5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2c89ab9-970a-4773-dd32-516978ffbe10"
      },
      "source": [
        "regressor = RandomForestRegressor(100, random_state=0)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.14750085071282282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-picjwK3I2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "361ac715-b1d8-49e1-d43c-0b476d8f19c6"
      },
      "source": [
        "regressor.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8504467717266132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IxYARxzGklh",
        "colab_type": "text"
      },
      "source": [
        "## 6.2 Evaluating the feature importances\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFpCh6L1rk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "17c9bbad-c45f-42f8-cff4-6cfb131c5009"
      },
      "source": [
        "pd.Series(regressor.feature_importances_, index=placed.drop(columns=['program_duration_days']).columns).sort_values(ascending =False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "number_of_applications                                              0.211023\n",
              "number_of_interviews                                                0.102410\n",
              "length_of_job_search                                                0.098034\n",
              "professional_experience                                             0.092051\n",
              "highest_level_of_education                                          0.074091\n",
              "employment_status _Student                                          0.033571\n",
              "primary_track_SWE                                                   0.028779\n",
              "work_authorization_status_Citizen                                   0.028299\n",
              "biggest_challenge_in_search_Hearing back on my applications         0.027944\n",
              "work_authorization_status_F1 Visa/OPT                               0.027228\n",
              "employment_status _Unemployed                                       0.027111\n",
              "biggest_challenge_in_search_Getting past final round interviews     0.025925\n",
              "employment_status _Employed Full-Time                               0.023457\n",
              "biggest_challenge_in_search_Getting past mid-stage interviews       0.020672\n",
              "biggest_challenge_in_search_Technical interviewing                  0.020467\n",
              "biggest_challenge_in_search_Lack of relevant experience             0.019365\n",
              "employment_status _Employed Part-Time                               0.017766\n",
              "biggest_challenge_in_search_Figuring out which jobs to apply for    0.016231\n",
              "biggest_challenge_in_search_Getting past phone screens              0.015868\n",
              "work_authorization_status_F1 Visa/CPT                               0.014306\n",
              "primary_track_Design                                                0.014089\n",
              "work_authorization_status_Green Card                                0.012857\n",
              "primary_track_PSO                                                   0.011605\n",
              "work_authorization_status_Other                                     0.010752\n",
              "biggest_challenge_in_search_Resume gap                              0.008730\n",
              "work_authorization_status_H1B                                       0.008351\n",
              "biggest_challenge_in_search_Technical skills                        0.006807\n",
              "work_authorization_status_STEM OPT                                  0.001755\n",
              "primary_track_Marketing                                             0.000255\n",
              "primary_track_Web                                                   0.000201\n",
              "pathrise_status_Withdrawn (Trial)                                   0.000000\n",
              "pathrise_status_Withdrawn (Failed)                                  0.000000\n",
              "work_authorization_status_Not Authorized                            0.000000\n",
              "pathrise_status_Break                                               0.000000\n",
              "pathrise_status_Closed Lost                                         0.000000\n",
              "pathrise_status_Deferred                                            0.000000\n",
              "pathrise_status_MIA                                                 0.000000\n",
              "pathrise_status_Placed                                              0.000000\n",
              "pathrise_status_Withdrawn                                           0.000000\n",
              "placed                                                              0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0z-kkgxHDZw",
        "colab_type": "text"
      },
      "source": [
        "## 6.3 SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fNbvaOSzKcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = preprocessing.MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikho2bdmze-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_ = scaler.fit_transform(X_train)\n",
        "X_test_ = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DDIym98uxaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "60d87235-02e8-47f3-8101-53a2490b4f87"
      },
      "source": [
        "regressor = SVR(kernel='poly', degree=5)\n",
        "regressor.fit(X_train_, y_train)\n",
        "y_pred = regressor.predict(X_test_)\n",
        "print(regressor.score(X_train_, y_train))\n",
        "print(r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.013571047391622737\n",
            "-0.06716702346649339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4yPUSSHOB7",
        "colab_type": "text"
      },
      "source": [
        "## 6.4 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzl09iG4sBET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9e21540-cc82-4b52-f8cb-795c5ff62fba"
      },
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X = (X_train), y=(y_train))\n",
        "y_pred = regressor.predict(X_test_)\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.04846288763640638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zn0kuJqHfmT",
        "colab_type": "text"
      },
      "source": [
        "## 6.5 Feature Extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3HtshKoDWT2",
        "colab_type": "text"
      },
      "source": [
        "### 6.5.1 LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqHK-IdPByE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LDA()\n",
        "X_train_original_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_original_lda = lda.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXGipYcnBx-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8cec11d-2175-4682-b2eb-0bdaf4fb429d"
      },
      "source": [
        "regressor = RandomForestRegressor(500, random_state=0, min_impurity_split=5, min_samples_split=5)\n",
        "regressor.fit(X_train_original_lda, y_train)\n",
        "y_pred = regressor.predict(X_test_original_lda)\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.06801153301001928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI8B-6e9Fl3p",
        "colab_type": "text"
      },
      "source": [
        "### 6.5.2 PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDg_LCkUFqG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=None)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VhqaIsqFp96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75902878-d752-4bb9-c545-aec77f8c3f56"
      },
      "source": [
        "regressor = RandomForestRegressor(500, random_state=0, max_features=30)\n",
        "regressor.fit(X_train_pca, y_train)\n",
        "y_pred = regressor.predict(X_test_pca)\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.08000400687889142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYLGolEJD6WZ",
        "colab_type": "text"
      },
      "source": [
        "### 6.5.3 Kernel PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqs1SFdCD_Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kpca = KernelPCA(kernel='rbf')\n",
        "X_train_original_kpca= kpca.fit_transform(X_train)\n",
        "X_test_original_kpca = kpca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYJN69rxD_Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8639dda4-4e5a-434c-edac-9585b92f42a9"
      },
      "source": [
        "regressor = RandomForestRegressor(500, random_state=0, max_features=30)\n",
        "regressor.fit(X_train_original_kpca, y_train)\n",
        "y_pred = regressor.predict(X_test_original_kpca)\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0013782001815587641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrRT6ZBrD_J2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41af85ab-daf2-433a-b9f2-48c2130d2712"
      },
      "source": [
        "regressor.score(X_train_original_kpca, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8611059247967452"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgbFmfhNJIQb",
        "colab_type": "text"
      },
      "source": [
        "## 6.6 Feature Engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ_6iHSrJ3VF",
        "colab_type": "text"
      },
      "source": [
        "### 6.6.1 Splitting program duration days in bins of width 10\n",
        "It is difficult to get an exact estimate of number of days it will take until the student is placed. So we split the 'program_duration_days' into smaller bins and try to estimate the length of the job search. \n",
        "\n",
        "The program_duration_days is originally a continuous valued feature and we will try to partition it into different bins. \n",
        "\n",
        "Before (placed):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407   |   59.0 \n",
        "478   |  46.0 \n",
        "490   |  94.0\n",
        "513   |  24.0\n",
        "1237  |  34.0\n",
        "\n",
        "\n",
        "After (placed1):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407  |   50.0\n",
        "478  |   40.0\n",
        "490  |   90.0\n",
        "513  |   20.0\n",
        "1237 |   30.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBcYpIHhBQ-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "placed1 = placed.copy()\n",
        "placed1.program_duration_days = (placed.program_duration_days  - (placed.program_duration_days % 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzpyfDErNZVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rf_regressor(data):\n",
        "  placed = data.copy()\n",
        "  placed.dropna(inplace=True)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(placed.drop(columns=['program_duration_days']), placed.program_duration_days, test_size = 0.2, random_state = 0)  \n",
        "  regressor = RandomForestRegressor(100, random_state=0)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "  return r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBb0AwNjNuSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd41da2d-0c83-4a7f-de3f-22e33e923ddd"
      },
      "source": [
        "rf_regressor(placed1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.14398598070520552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVk-j_gOMmxe",
        "colab_type": "text"
      },
      "source": [
        "### 6.6.2 Splitting program duration days in bins of width 15\n",
        "\n",
        "Before (placed):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407   |   59.0 \n",
        "478   |  46.0 \n",
        "490   |  94.0\n",
        "513   |  24.0\n",
        "1237  |  34.0\n",
        "\n",
        "\n",
        "After (placed2):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407  |    60\n",
        "478  |    60\n",
        "490  |   105\n",
        "513  |    30\n",
        "1237 |    45\n",
        "\n",
        "Categories (36, int64): [15 < 30 < 45 < 60 ... 495 < 510 < 525 < 540]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3DZao1HK7gW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06d801e-6af9-49b4-da99-4220d96d19fc"
      },
      "source": [
        "placed2 = placed.copy()\n",
        "placed2.program_duration_days = pd.cut(placed.program_duration_days, range(0,550, 15), include_lowest=True, labels= [i*15 for i in range(1,37)])\n",
        "rf_regressor(placed2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10849678562507181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23ZXiHN7Fa2",
        "colab_type": "text"
      },
      "source": [
        "### 6.6.3 Splitting program duration days in bins of width 30\n",
        "\n",
        "Before (placed):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407   |   59.0 \n",
        "478   |  46.0 \n",
        "490   |  94.0\n",
        "513   |  24.0\n",
        "1237  |  34.0\n",
        "\n",
        "\n",
        "After (placed3):\n",
        "\n",
        "Index | program_duration_days\n",
        "--- | ---\n",
        "407  |    60\n",
        "478  |    60\n",
        "490  |   120\n",
        "513  |    30\n",
        "1237 |    60\n",
        "\n",
        "Categories (18, int64): [30 < 60 < 90 < 120 ... 450 < 480 < 510 < 540]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6rsgDBGNCZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba5c6a16-14ad-4ee1-84a7-095f4e3a4e58"
      },
      "source": [
        "placed3 = placed.copy()\n",
        "placed3.program_duration_days =pd.cut(placed.program_duration_days, range(0,550, 30), include_lowest=True, labels= [i*30 for i in range(1,19)])\n",
        "rf_regressor(placed3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.09258632327461758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a6He9HrPbVh",
        "colab_type": "text"
      },
      "source": [
        "#### 6.6.3.1 Adding cosine sililarity feature to the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQB6jfYBOtjp",
        "colab_type": "text"
      },
      "source": [
        "<h1>The approach is sligtly improving the R-squared score. However, the score is still in negatives which means the predictions are pretty random. Thus this method is not suitable for prediction.\n",
        "\n",
        "<h2>Let's include the **cosine similarity** feature to the dataset and evaluate the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiXmpcsSQaXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7c2ca06-d7b1-4534-9423-afd70fa0638e"
      },
      "source": [
        "placed3['cosine_similarity'] = similarity_placed\n",
        "rf_regressor(placed3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7797648699517347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rU3nVoMISpk",
        "colab_type": "text"
      },
      "source": [
        "### KFold CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP9JsX2I5Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold(data):\n",
        "  placed = data.copy()\n",
        "  placed.dropna(inplace=True)\n",
        "  X,y = placed.drop(columns=['program_duration_days']), placed.program_duration_days\n",
        "  kfolds = KFold(shuffle=True, random_state=0)\n",
        "  folds =  kfolds.split(X,y)\n",
        "  return folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmu4IwpJdzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv(data):\n",
        "  placed = data.copy()\n",
        "  placed.dropna(inplace=True)\n",
        "  \n",
        "  y_test_r2_score_ = []\n",
        "  folds = kfold(placed3)\n",
        "  X,y = placed.drop(columns=['program_duration_days']), placed.program_duration_days\n",
        "\n",
        "  for fold in folds:\n",
        "    X_train, X_test, y_train, y_test = X.values[fold[0]], X.values[fold[1]], y.values[fold[0]], y.values[fold[1]]\n",
        "    regressor = RandomForestRegressor(100, random_state=0)\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_test_r2_score_.append(regressor.score(X_test, y_test))\n",
        "\n",
        "  return np.array(y_test_r2_score_).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxGsWeJ8MbNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62b624d1-e0b5-4bd3-f60a-430ee2f726fd"
      },
      "source": [
        "cv(placed3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6958803630334769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440sp-6uMuKR",
        "colab_type": "text"
      },
      "source": [
        "<h1>The accuracy is about 69.5%. we can tune the hyperparameters by using GridSearch and try to further enhance the accuracy of the model. </h1> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ76ibw4SYNI",
        "colab_type": "text"
      },
      "source": [
        "### GridSearch CV for hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KANhBuf-Rzga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gridsearch_cv(data, parameters):\n",
        "  placed = data.copy()\n",
        "  placed.dropna(inplace=True)\n",
        "  X, y = placed.drop(columns=['program_duration_days']), placed.program_duration_days\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=0)\n",
        "\n",
        "  grid_cv = GridSearchCV(rf, parameters, verbose=10, return_train_score=True)\n",
        "  grid_cv.fit(X,y)\n",
        "  \n",
        "  return grid_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvs8Dm2Nd89c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a7aface-07c4-49bc-8c20-c2f2d2244123"
      },
      "source": [
        "params = {'n_estimators':[100,150,200,250,300, 400, 500],'min_samples_leaf':[1], 'min_samples_split':[2]}\n",
        "grid_cv = gridsearch_cv(placed3, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.954, test=0.726), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.958, test=0.767), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.960, test=0.620), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.955, test=0.703), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.962, test=0.689), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.955, test=0.721), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.958, test=0.766), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.961, test=0.625), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    4.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.956, test=0.704), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.961, test=0.687), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.956, test=0.721), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.958, test=0.760), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.961, test=0.630), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.957, test=0.705), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.962, test=0.690), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.956, test=0.720), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.958, test=0.756), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.961, test=0.631), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.957, test=0.708), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.962, test=0.692), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.956, test=0.719), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.958, test=0.760), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.961, test=0.626), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.957, test=0.706), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.963, test=0.690), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=400 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=(train=0.956, test=0.720), total=   1.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=400 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=(train=0.958, test=0.760), total=   1.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=400 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=(train=0.961, test=0.626), total=   1.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=400 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=(train=0.958, test=0.707), total=   1.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=400 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=(train=0.963, test=0.693), total=   1.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=500 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=(train=0.956, test=0.719), total=   1.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=500 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=(train=0.957, test=0.761), total=   1.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=500 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=(train=0.961, test=0.630), total=   1.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=500 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=(train=0.958, test=0.709), total=   1.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=500 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=(train=0.963, test=0.693), total=   1.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   38.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veNMUwZ8eUOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ad19631-6502-4938-eb89-c36ddd46a5fa"
      },
      "source": [
        "grid_cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7025241815370287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar39rMVVeXi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4c04dca8-0a65-42e7-b292-99a638644665"
      },
      "source": [
        "grid_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
              "                      random_state=0, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL3tCPjTeUF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09792c8b-c950-40b6-e71b-ad162c914102"
      },
      "source": [
        "params = {'n_estimators':[100,150,200,250,300] ,'min_samples_leaf':[1, 2, 5, 10, 20], 'min_samples_split':[2,4,6,8,10]}\n",
        "grid_cv = gridsearch_cv(placed3, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 125 candidates, totalling 625 fits\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.954, test=0.726), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.958, test=0.767), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.960, test=0.620), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.955, test=0.703), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=100 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=(train=0.962, test=0.689), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.955, test=0.721), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.958, test=0.766), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.961, test=0.625), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.956, test=0.704), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=150 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=150, score=(train=0.961, test=0.687), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.956, test=0.721), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.958, test=0.760), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.961, test=0.630), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.957, test=0.705), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=(train=0.962, test=0.690), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.956, test=0.720), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.958, test=0.756), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.961, test=0.631), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.957, test=0.708), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=250, score=(train=0.962, test=0.692), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.956, test=0.719), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.958, test=0.760), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.961, test=0.626), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.957, test=0.706), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=2, n_estimators=300, score=(train=0.963, test=0.690), total=   1.2s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=(train=0.943, test=0.732), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=(train=0.945, test=0.759), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=(train=0.950, test=0.618), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=(train=0.944, test=0.702), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=(train=0.953, test=0.686), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=150, score=(train=0.944, test=0.725), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=150, score=(train=0.946, test=0.759), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=150, score=(train=0.951, test=0.621), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=150, score=(train=0.945, test=0.707), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=150, score=(train=0.953, test=0.685), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=(train=0.945, test=0.723), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=(train=0.947, test=0.755), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=(train=0.951, test=0.627), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=(train=0.947, test=0.704), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=(train=0.954, test=0.688), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=250, score=(train=0.944, test=0.723), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=250, score=(train=0.947, test=0.752), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=250, score=(train=0.951, test=0.626), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=250, score=(train=0.947, test=0.707), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=250, score=(train=0.954, test=0.690), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=300, score=(train=0.945, test=0.720), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=300, score=(train=0.946, test=0.758), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=300, score=(train=0.951, test=0.620), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=300, score=(train=0.947, test=0.707), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=4, n_estimators=300, score=(train=0.954, test=0.687), total=   1.1s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=100, score=(train=0.929, test=0.727), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=100, score=(train=0.930, test=0.761), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=100, score=(train=0.939, test=0.627), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=100, score=(train=0.931, test=0.695), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=100, score=(train=0.940, test=0.683), total=   0.4s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=150, score=(train=0.930, test=0.721), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=150, score=(train=0.931, test=0.761), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=150, score=(train=0.939, test=0.630), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=150, score=(train=0.931, test=0.697), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=150, score=(train=0.940, test=0.682), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=200, score=(train=0.931, test=0.721), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=200, score=(train=0.931, test=0.756), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=200, score=(train=0.939, test=0.632), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=200, score=(train=0.933, test=0.698), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=200, score=(train=0.940, test=0.685), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=250, score=(train=0.931, test=0.720), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=250, score=(train=0.931, test=0.753), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=250, score=(train=0.939, test=0.630), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=250, score=(train=0.933, test=0.700), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=250, score=(train=0.940, test=0.687), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=300, score=(train=0.931, test=0.718), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=300, score=(train=0.931, test=0.758), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=300, score=(train=0.938, test=0.625), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=300, score=(train=0.933, test=0.699), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=6, n_estimators=300, score=(train=0.940, test=0.684), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=(train=0.913, test=0.722), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=(train=0.913, test=0.756), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=(train=0.922, test=0.614), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=(train=0.916, test=0.697), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=(train=0.924, test=0.677), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=150, score=(train=0.915, test=0.716), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=150, score=(train=0.914, test=0.757), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=150, score=(train=0.923, test=0.619), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=150, score=(train=0.916, test=0.697), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=150, score=(train=0.924, test=0.677), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=(train=0.916, test=0.713), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=(train=0.915, test=0.753), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=(train=0.923, test=0.623), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=(train=0.919, test=0.697), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=(train=0.924, test=0.680), total=   0.7s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=250, score=(train=0.915, test=0.712), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=250, score=(train=0.915, test=0.749), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=250, score=(train=0.923, test=0.622), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=250, score=(train=0.918, test=0.700), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=250, score=(train=0.924, test=0.681), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=300, score=(train=0.916, test=0.710), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=300, score=(train=0.915, test=0.756), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=300, score=(train=0.923, test=0.617), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=300, score=(train=0.919, test=0.698), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=8, n_estimators=300, score=(train=0.924, test=0.678), total=   1.0s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=(train=0.896, test=0.715), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=(train=0.896, test=0.750), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=(train=0.907, test=0.612), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=(train=0.900, test=0.694), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=(train=0.907, test=0.671), total=   0.3s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=150, score=(train=0.898, test=0.709), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=150, score=(train=0.897, test=0.752), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=150, score=(train=0.907, test=0.617), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=150, score=(train=0.900, test=0.691), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=150, score=(train=0.907, test=0.670), total=   0.5s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=(train=0.899, test=0.706), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=(train=0.897, test=0.748), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=(train=0.907, test=0.618), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=(train=0.902, test=0.690), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=(train=0.908, test=0.674), total=   0.6s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=250, score=(train=0.899, test=0.704), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=250, score=(train=0.898, test=0.745), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=250, score=(train=0.907, test=0.617), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=250, score=(train=0.902, test=0.694), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=250, score=(train=0.908, test=0.675), total=   0.8s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=300, score=(train=0.900, test=0.703), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=300, score=(train=0.898, test=0.751), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=300, score=(train=0.907, test=0.615), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=300, score=(train=0.903, test=0.692), total=   0.9s\n",
            "[CV] min_samples_leaf=1, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=1, min_samples_split=10, n_estimators=300, score=(train=0.907, test=0.673), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=100, score=(train=0.917, test=0.730), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=100, score=(train=0.922, test=0.755), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=100, score=(train=0.929, test=0.601), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=100, score=(train=0.924, test=0.670), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=100, score=(train=0.929, test=0.701), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=150, score=(train=0.919, test=0.724), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=150, score=(train=0.923, test=0.755), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=150, score=(train=0.929, test=0.606), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=150, score=(train=0.925, test=0.672), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=150, score=(train=0.930, test=0.698), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=(train=0.920, test=0.723), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=(train=0.924, test=0.750), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=(train=0.929, test=0.609), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=(train=0.927, test=0.669), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=(train=0.931, test=0.702), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=250, score=(train=0.920, test=0.722), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=250, score=(train=0.924, test=0.745), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=250, score=(train=0.929, test=0.604), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=250, score=(train=0.926, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=250, score=(train=0.931, test=0.705), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=300, score=(train=0.920, test=0.719), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=300, score=(train=0.924, test=0.750), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=300, score=(train=0.929, test=0.601), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=300, score=(train=0.926, test=0.671), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=2, n_estimators=300, score=(train=0.931, test=0.702), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=100, score=(train=0.917, test=0.730), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=100, score=(train=0.922, test=0.755), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=100, score=(train=0.929, test=0.601), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=100, score=(train=0.924, test=0.670), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=100, score=(train=0.929, test=0.701), total=   0.4s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=150, score=(train=0.919, test=0.724), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=150, score=(train=0.923, test=0.755), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=150, score=(train=0.929, test=0.606), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=150, score=(train=0.925, test=0.672), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=150, score=(train=0.930, test=0.698), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=200, score=(train=0.920, test=0.723), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=200, score=(train=0.924, test=0.750), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=200, score=(train=0.929, test=0.609), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=200, score=(train=0.927, test=0.669), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=200, score=(train=0.931, test=0.702), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=250, score=(train=0.920, test=0.722), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=250, score=(train=0.924, test=0.745), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=250, score=(train=0.929, test=0.604), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=250, score=(train=0.926, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=250, score=(train=0.931, test=0.705), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=300, score=(train=0.920, test=0.719), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=300, score=(train=0.924, test=0.750), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=300, score=(train=0.929, test=0.601), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=300, score=(train=0.926, test=0.671), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=4, n_estimators=300, score=(train=0.931, test=0.702), total=   1.1s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=100, score=(train=0.902, test=0.729), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=100, score=(train=0.905, test=0.752), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=100, score=(train=0.914, test=0.599), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=100, score=(train=0.909, test=0.664), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=100, score=(train=0.914, test=0.696), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=150, score=(train=0.904, test=0.722), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=150, score=(train=0.906, test=0.753), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=150, score=(train=0.914, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=150, score=(train=0.910, test=0.667), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=150, score=(train=0.916, test=0.693), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=200, score=(train=0.905, test=0.721), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=200, score=(train=0.907, test=0.749), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=200, score=(train=0.914, test=0.609), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=200, score=(train=0.912, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=200, score=(train=0.917, test=0.697), total=   0.7s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=250, score=(train=0.905, test=0.721), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=250, score=(train=0.907, test=0.744), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=250, score=(train=0.915, test=0.603), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=250, score=(train=0.912, test=0.666), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=250, score=(train=0.916, test=0.701), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=300, score=(train=0.905, test=0.718), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=300, score=(train=0.907, test=0.749), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=300, score=(train=0.915, test=0.601), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=300, score=(train=0.911, test=0.667), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=6, n_estimators=300, score=(train=0.916, test=0.698), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=100, score=(train=0.885, test=0.721), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=100, score=(train=0.885, test=0.749), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=100, score=(train=0.899, test=0.597), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=100, score=(train=0.893, test=0.662), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=100, score=(train=0.898, test=0.691), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=150, score=(train=0.886, test=0.717), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=150, score=(train=0.887, test=0.750), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=150, score=(train=0.899, test=0.605), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=150, score=(train=0.894, test=0.667), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=150, score=(train=0.899, test=0.689), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=200, score=(train=0.888, test=0.715), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=200, score=(train=0.888, test=0.747), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=200, score=(train=0.899, test=0.609), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=200, score=(train=0.896, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=200, score=(train=0.900, test=0.693), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=250, score=(train=0.888, test=0.716), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=250, score=(train=0.888, test=0.742), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=250, score=(train=0.900, test=0.603), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=250, score=(train=0.896, test=0.667), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=250, score=(train=0.900, test=0.697), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=300, score=(train=0.888, test=0.713), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=300, score=(train=0.889, test=0.747), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=300, score=(train=0.900, test=0.601), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=300, score=(train=0.896, test=0.668), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=8, n_estimators=300, score=(train=0.900, test=0.694), total=   1.0s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=100, score=(train=0.869, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=100, score=(train=0.869, test=0.747), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=100, score=(train=0.883, test=0.595), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=100, score=(train=0.878, test=0.658), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=100, score=(train=0.883, test=0.684), total=   0.3s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=150, score=(train=0.870, test=0.711), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=150, score=(train=0.871, test=0.748), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=150, score=(train=0.883, test=0.602), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=150, score=(train=0.878, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=150, score=(train=0.883, test=0.682), total=   0.5s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=200, score=(train=0.871, test=0.709), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=200, score=(train=0.872, test=0.745), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=200, score=(train=0.884, test=0.606), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=200, score=(train=0.881, test=0.660), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=200, score=(train=0.885, test=0.686), total=   0.6s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=250, score=(train=0.871, test=0.708), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=250, score=(train=0.872, test=0.740), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=250, score=(train=0.884, test=0.601), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=250, score=(train=0.880, test=0.663), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=250, score=(train=0.884, test=0.689), total=   0.8s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=300, score=(train=0.872, test=0.706), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=300, score=(train=0.872, test=0.744), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=300, score=(train=0.884, test=0.599), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=300, score=(train=0.881, test=0.663), total=   0.9s\n",
            "[CV] min_samples_leaf=2, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=2, min_samples_split=10, n_estimators=300, score=(train=0.884, test=0.686), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=(train=0.814, test=0.707), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=(train=0.815, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=(train=0.841, test=0.613), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=(train=0.833, test=0.673), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=(train=0.841, test=0.668), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=150, score=(train=0.816, test=0.709), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=150, score=(train=0.817, test=0.715), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=150, score=(train=0.840, test=0.610), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=150, score=(train=0.830, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=150, score=(train=0.841, test=0.668), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=(train=0.816, test=0.710), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=(train=0.818, test=0.713), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=(train=0.841, test=0.615), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=(train=0.831, test=0.675), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=(train=0.841, test=0.669), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=250, score=(train=0.817, test=0.711), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=250, score=(train=0.818, test=0.715), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=250, score=(train=0.842, test=0.611), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=250, score=(train=0.831, test=0.674), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=250, score=(train=0.841, test=0.672), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=300, score=(train=0.817, test=0.709), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=300, score=(train=0.818, test=0.716), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=300, score=(train=0.843, test=0.609), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=300, score=(train=0.831, test=0.672), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=2, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=2, n_estimators=300, score=(train=0.841, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=(train=0.814, test=0.707), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=(train=0.815, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=(train=0.841, test=0.613), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=(train=0.833, test=0.673), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=(train=0.841, test=0.668), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=150, score=(train=0.816, test=0.709), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=150, score=(train=0.817, test=0.715), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=150, score=(train=0.840, test=0.610), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=150, score=(train=0.830, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=150, score=(train=0.841, test=0.668), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=(train=0.816, test=0.710), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=(train=0.818, test=0.713), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=(train=0.841, test=0.615), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=(train=0.831, test=0.675), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=(train=0.841, test=0.669), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=250, score=(train=0.817, test=0.711), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=250, score=(train=0.818, test=0.715), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=250, score=(train=0.842, test=0.611), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=250, score=(train=0.831, test=0.674), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=250, score=(train=0.841, test=0.672), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=300, score=(train=0.817, test=0.709), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=300, score=(train=0.818, test=0.716), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=300, score=(train=0.843, test=0.609), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=300, score=(train=0.831, test=0.672), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=4, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=4, n_estimators=300, score=(train=0.841, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=100, score=(train=0.814, test=0.707), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=100, score=(train=0.815, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=100, score=(train=0.841, test=0.613), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=100, score=(train=0.833, test=0.673), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=100, score=(train=0.841, test=0.668), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=150, score=(train=0.816, test=0.709), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=150, score=(train=0.817, test=0.715), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=150, score=(train=0.840, test=0.610), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=150, score=(train=0.830, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=150, score=(train=0.841, test=0.668), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=200, score=(train=0.816, test=0.710), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=200, score=(train=0.818, test=0.713), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=200, score=(train=0.841, test=0.615), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=200, score=(train=0.831, test=0.675), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=200, score=(train=0.841, test=0.669), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=250, score=(train=0.817, test=0.711), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=250, score=(train=0.818, test=0.715), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=250, score=(train=0.842, test=0.611), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=250, score=(train=0.831, test=0.674), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=250, score=(train=0.841, test=0.672), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=300, score=(train=0.817, test=0.709), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=300, score=(train=0.818, test=0.716), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=300, score=(train=0.843, test=0.609), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=300, score=(train=0.831, test=0.672), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=6, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=6, n_estimators=300, score=(train=0.841, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=(train=0.814, test=0.707), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=(train=0.815, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=(train=0.841, test=0.613), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=(train=0.833, test=0.673), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=100 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=(train=0.841, test=0.668), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=150, score=(train=0.816, test=0.709), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=150, score=(train=0.817, test=0.715), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=150, score=(train=0.840, test=0.610), total=   0.5s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=150, score=(train=0.830, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=150 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=150, score=(train=0.841, test=0.668), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=(train=0.816, test=0.710), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=(train=0.818, test=0.713), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=(train=0.841, test=0.615), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=(train=0.831, test=0.675), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=200 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=(train=0.841, test=0.669), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=250, score=(train=0.817, test=0.711), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=250, score=(train=0.818, test=0.715), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=250, score=(train=0.842, test=0.611), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=250, score=(train=0.831, test=0.674), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=250 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=250, score=(train=0.841, test=0.672), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=300, score=(train=0.817, test=0.709), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=300, score=(train=0.818, test=0.716), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=300, score=(train=0.843, test=0.609), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=300, score=(train=0.831, test=0.672), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=8, n_estimators=300 .......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=8, n_estimators=300, score=(train=0.841, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=(train=0.814, test=0.707), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=(train=0.815, test=0.717), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=(train=0.841, test=0.613), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=(train=0.833, test=0.673), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=(train=0.841, test=0.668), total=   0.3s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=150, score=(train=0.816, test=0.709), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=150, score=(train=0.817, test=0.715), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=150, score=(train=0.840, test=0.610), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=150, score=(train=0.830, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=150, score=(train=0.841, test=0.668), total=   0.4s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=(train=0.816, test=0.710), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=(train=0.818, test=0.713), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=(train=0.841, test=0.615), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=(train=0.831, test=0.675), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=(train=0.841, test=0.669), total=   0.6s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=250, score=(train=0.817, test=0.711), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=250, score=(train=0.818, test=0.715), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=250, score=(train=0.842, test=0.611), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=250, score=(train=0.831, test=0.674), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=250, score=(train=0.841, test=0.672), total=   0.7s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=300, score=(train=0.817, test=0.709), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=300, score=(train=0.818, test=0.716), total=   0.8s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=300, score=(train=0.843, test=0.609), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=300, score=(train=0.831, test=0.672), total=   0.9s\n",
            "[CV] min_samples_leaf=5, min_samples_split=10, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=5, min_samples_split=10, n_estimators=300, score=(train=0.841, test=0.670), total=   0.9s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=(train=0.714, test=0.661), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=(train=0.716, test=0.679), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=(train=0.749, test=0.565), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=(train=0.735, test=0.631), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=(train=0.735, test=0.601), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=150, score=(train=0.714, test=0.663), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=150, score=(train=0.716, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=150, score=(train=0.749, test=0.565), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=150, score=(train=0.734, test=0.633), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=150, score=(train=0.736, test=0.603), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=(train=0.713, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=(train=0.717, test=0.674), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=(train=0.749, test=0.567), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=(train=0.735, test=0.635), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=(train=0.738, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=250, score=(train=0.714, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=250, score=(train=0.717, test=0.676), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=250, score=(train=0.751, test=0.567), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=250, score=(train=0.735, test=0.636), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=250, score=(train=0.739, test=0.608), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=300, score=(train=0.714, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=300, score=(train=0.718, test=0.679), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=300, score=(train=0.752, test=0.566), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=300, score=(train=0.736, test=0.635), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=2, n_estimators=300, score=(train=0.739, test=0.608), total=   0.8s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=(train=0.714, test=0.661), total=   0.2s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=(train=0.716, test=0.679), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=(train=0.749, test=0.565), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=(train=0.735, test=0.631), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=(train=0.735, test=0.601), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=150, score=(train=0.714, test=0.663), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=150, score=(train=0.716, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=150, score=(train=0.749, test=0.565), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=150, score=(train=0.734, test=0.633), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=150, score=(train=0.736, test=0.603), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=(train=0.713, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=(train=0.717, test=0.674), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=(train=0.749, test=0.567), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=(train=0.735, test=0.635), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=(train=0.738, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=250, score=(train=0.714, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=250, score=(train=0.717, test=0.676), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=250, score=(train=0.751, test=0.567), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=250, score=(train=0.735, test=0.636), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=250, score=(train=0.739, test=0.608), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=300, score=(train=0.714, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=300, score=(train=0.718, test=0.679), total=   0.8s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=300, score=(train=0.752, test=0.566), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=300, score=(train=0.736, test=0.635), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=4, n_estimators=300, score=(train=0.739, test=0.608), total=   0.8s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=100, score=(train=0.714, test=0.661), total=   0.2s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=100, score=(train=0.716, test=0.679), total=   0.2s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=100, score=(train=0.749, test=0.565), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=100, score=(train=0.735, test=0.631), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=100, score=(train=0.735, test=0.601), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=150, score=(train=0.714, test=0.663), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=150, score=(train=0.716, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=150, score=(train=0.749, test=0.565), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=150, score=(train=0.734, test=0.633), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=150, score=(train=0.736, test=0.603), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=200, score=(train=0.713, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=200, score=(train=0.717, test=0.674), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=200, score=(train=0.749, test=0.567), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=200, score=(train=0.735, test=0.635), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=200, score=(train=0.738, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=250, score=(train=0.714, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=250, score=(train=0.717, test=0.676), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=250, score=(train=0.751, test=0.567), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=250, score=(train=0.735, test=0.636), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=250, score=(train=0.739, test=0.608), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=300, score=(train=0.714, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=300, score=(train=0.718, test=0.679), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=300, score=(train=0.752, test=0.566), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=300, score=(train=0.736, test=0.635), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=6, n_estimators=300, score=(train=0.739, test=0.608), total=   0.8s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=(train=0.714, test=0.661), total=   0.2s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=(train=0.716, test=0.679), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=(train=0.749, test=0.565), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=(train=0.735, test=0.631), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=(train=0.735, test=0.601), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=150, score=(train=0.714, test=0.663), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=150, score=(train=0.716, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=150, score=(train=0.749, test=0.565), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=150, score=(train=0.734, test=0.633), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=150, score=(train=0.736, test=0.603), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=(train=0.713, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=(train=0.717, test=0.674), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=(train=0.749, test=0.567), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=(train=0.735, test=0.635), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=(train=0.738, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=250, score=(train=0.714, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=250, score=(train=0.717, test=0.676), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=250, score=(train=0.751, test=0.567), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=250, score=(train=0.735, test=0.636), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=250, score=(train=0.739, test=0.608), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=300, score=(train=0.714, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=300, score=(train=0.718, test=0.679), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=300, score=(train=0.752, test=0.566), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=300, score=(train=0.736, test=0.635), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=10, min_samples_split=8, n_estimators=300, score=(train=0.739, test=0.608), total=   0.8s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=(train=0.714, test=0.661), total=   0.2s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=(train=0.716, test=0.679), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=(train=0.749, test=0.565), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=(train=0.735, test=0.631), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=(train=0.735, test=0.601), total=   0.3s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=150, score=(train=0.714, test=0.663), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=150, score=(train=0.716, test=0.676), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=150, score=(train=0.749, test=0.565), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=150, score=(train=0.734, test=0.633), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=150, score=(train=0.736, test=0.603), total=   0.4s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=(train=0.713, test=0.662), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=(train=0.717, test=0.674), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=(train=0.749, test=0.567), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=(train=0.735, test=0.635), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=(train=0.738, test=0.604), total=   0.5s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=250, score=(train=0.714, test=0.664), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=250, score=(train=0.717, test=0.676), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=250, score=(train=0.751, test=0.567), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=250, score=(train=0.735, test=0.636), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=250, score=(train=0.739, test=0.608), total=   0.6s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=300, score=(train=0.714, test=0.664), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=300, score=(train=0.718, test=0.679), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=300, score=(train=0.752, test=0.566), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=300, score=(train=0.736, test=0.635), total=   0.7s\n",
            "[CV] min_samples_leaf=10, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=10, min_samples_split=10, n_estimators=300, score=(train=0.739, test=0.608), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=100, score=(train=0.607, test=0.583), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=100, score=(train=0.601, test=0.605), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=100, score=(train=0.636, test=0.504), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=100, score=(train=0.629, test=0.574), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=100, score=(train=0.627, test=0.531), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=150, score=(train=0.608, test=0.581), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=150, score=(train=0.600, test=0.603), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=150, score=(train=0.636, test=0.506), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=150, score=(train=0.628, test=0.572), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=150, score=(train=0.629, test=0.535), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=200, score=(train=0.607, test=0.580), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=200, score=(train=0.602, test=0.605), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=200, score=(train=0.637, test=0.508), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=200, score=(train=0.627, test=0.574), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=200, score=(train=0.629, test=0.536), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=250, score=(train=0.609, test=0.582), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=250, score=(train=0.603, test=0.607), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=250, score=(train=0.636, test=0.507), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=250, score=(train=0.627, test=0.572), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=250, score=(train=0.630, test=0.539), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=300, score=(train=0.609, test=0.582), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=300, score=(train=0.605, test=0.610), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=300, score=(train=0.637, test=0.506), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=300, score=(train=0.627, test=0.572), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=2, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=2, n_estimators=300, score=(train=0.630, test=0.540), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=100, score=(train=0.607, test=0.583), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=100, score=(train=0.601, test=0.605), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=100, score=(train=0.636, test=0.504), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=100, score=(train=0.629, test=0.574), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=100, score=(train=0.627, test=0.531), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=150, score=(train=0.608, test=0.581), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=150, score=(train=0.600, test=0.603), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=150, score=(train=0.636, test=0.506), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=150, score=(train=0.628, test=0.572), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=150, score=(train=0.629, test=0.535), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=200, score=(train=0.607, test=0.580), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=200, score=(train=0.602, test=0.605), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=200, score=(train=0.637, test=0.508), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=200, score=(train=0.627, test=0.574), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=200, score=(train=0.629, test=0.536), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=250, score=(train=0.609, test=0.582), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=250, score=(train=0.603, test=0.607), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=250, score=(train=0.636, test=0.507), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=250, score=(train=0.627, test=0.572), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=250, score=(train=0.630, test=0.539), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=300, score=(train=0.609, test=0.582), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=300, score=(train=0.605, test=0.610), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=300, score=(train=0.637, test=0.506), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=300, score=(train=0.627, test=0.572), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=4, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=4, n_estimators=300, score=(train=0.630, test=0.540), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=100, score=(train=0.607, test=0.583), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=100, score=(train=0.601, test=0.605), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=100, score=(train=0.636, test=0.504), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=100, score=(train=0.629, test=0.574), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=100, score=(train=0.627, test=0.531), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=150, score=(train=0.608, test=0.581), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=150, score=(train=0.600, test=0.603), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=150, score=(train=0.636, test=0.506), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=150, score=(train=0.628, test=0.572), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=150, score=(train=0.629, test=0.535), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=200, score=(train=0.607, test=0.580), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=200, score=(train=0.602, test=0.605), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=200, score=(train=0.637, test=0.508), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=200, score=(train=0.627, test=0.574), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=200, score=(train=0.629, test=0.536), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=250, score=(train=0.609, test=0.582), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=250, score=(train=0.603, test=0.607), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=250, score=(train=0.636, test=0.507), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=250, score=(train=0.627, test=0.572), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=250, score=(train=0.630, test=0.539), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=300, score=(train=0.609, test=0.582), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=300, score=(train=0.605, test=0.610), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=300, score=(train=0.637, test=0.506), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=300, score=(train=0.627, test=0.572), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=6, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=6, n_estimators=300, score=(train=0.630, test=0.540), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=100, score=(train=0.607, test=0.583), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=100, score=(train=0.601, test=0.605), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=100, score=(train=0.636, test=0.504), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=100, score=(train=0.629, test=0.574), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=100 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=100, score=(train=0.627, test=0.531), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=150, score=(train=0.608, test=0.581), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=150, score=(train=0.600, test=0.603), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=150, score=(train=0.636, test=0.506), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=150, score=(train=0.628, test=0.572), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=150 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=150, score=(train=0.629, test=0.535), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=200, score=(train=0.607, test=0.580), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=200, score=(train=0.602, test=0.605), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=200, score=(train=0.637, test=0.508), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=200, score=(train=0.627, test=0.574), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=200 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=200, score=(train=0.629, test=0.536), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=250, score=(train=0.609, test=0.582), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=250, score=(train=0.603, test=0.607), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=250, score=(train=0.636, test=0.507), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=250, score=(train=0.627, test=0.572), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=250 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=250, score=(train=0.630, test=0.539), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=300, score=(train=0.609, test=0.582), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=300, score=(train=0.605, test=0.610), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=300, score=(train=0.637, test=0.506), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=300, score=(train=0.627, test=0.572), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=8, n_estimators=300 ......\n",
            "[CV]  min_samples_leaf=20, min_samples_split=8, n_estimators=300, score=(train=0.630, test=0.540), total=   0.7s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=100, score=(train=0.607, test=0.583), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=100, score=(train=0.601, test=0.605), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=100, score=(train=0.636, test=0.504), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=100, score=(train=0.629, test=0.574), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=100 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=100, score=(train=0.627, test=0.531), total=   0.2s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=150, score=(train=0.608, test=0.581), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=150, score=(train=0.600, test=0.603), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=150, score=(train=0.636, test=0.506), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=150, score=(train=0.628, test=0.572), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=150 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=150, score=(train=0.629, test=0.535), total=   0.3s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=200, score=(train=0.607, test=0.580), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=200, score=(train=0.602, test=0.605), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=200, score=(train=0.637, test=0.508), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=200, score=(train=0.627, test=0.574), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=200 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=200, score=(train=0.629, test=0.536), total=   0.4s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=250, score=(train=0.609, test=0.582), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=250, score=(train=0.603, test=0.607), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=250, score=(train=0.636, test=0.507), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=250, score=(train=0.627, test=0.572), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=250 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=250, score=(train=0.630, test=0.539), total=   0.5s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=300, score=(train=0.609, test=0.582), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=300, score=(train=0.605, test=0.610), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=300, score=(train=0.637, test=0.506), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=300, score=(train=0.627, test=0.572), total=   0.6s\n",
            "[CV] min_samples_leaf=20, min_samples_split=10, n_estimators=300 .....\n",
            "[CV]  min_samples_leaf=20, min_samples_split=10, n_estimators=300, score=(train=0.630, test=0.540), total=   0.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 625 out of 625 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfxQN5oReT8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c73475a1-951b-40ae-d378-7a20b62c1d2e"
      },
      "source": [
        "grid_cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7011823718394504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdTFt5mAgb0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "e0c53e61-db5c-451c-947e-92bfe2abebb9"
      },
      "source": [
        "grid_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
              "                      random_state=0, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIpa1MwXLBlf",
        "colab_type": "text"
      },
      "source": [
        "# 7. Classification Model: Classifying placed vs unplaced candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGzoFDcAuAMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912,
          "referenced_widgets": [
            "3a764fa0266d496694ef8862ff62a85b",
            "35042cee6d654488b722eb2bb95ace51",
            "a6c3711219cb4147875ca0343ef1b329",
            "bab8357589254fe480401e56b10f830b",
            "b4a7e69161a946b784bd859bb803cd94",
            "6fb8d46d519248f5b28b45f1001cb20d"
          ]
        },
        "outputId": "05c22a24-ff51-4623-b9d2-b37753c89006"
      },
      "source": [
        "from pycaret.classification import *\n",
        "clf1 = setup(data = data1, target = 'placed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            "Setup Succesfully Completed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row0_col1\" class=\"data row0 col1\" >1337</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Target Type</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row1_col1\" class=\"data row1 col1\" >Binary</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Label Encoded</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row2_col1\" class=\"data row2 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Original Data</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row3_col1\" class=\"data row3 col1\" >(2536, 41)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Missing Values </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row4_col1\" class=\"data row4 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Numeric Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row5_col1\" class=\"data row5 col1\" >37</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Categorical Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row6_col1\" class=\"data row6 col1\" >3</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row7_col0\" class=\"data row7 col0\" >Ordinal Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row7_col1\" class=\"data row7 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row8_col0\" class=\"data row8 col0\" >High Cardinality Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row8_col1\" class=\"data row8 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row9_col0\" class=\"data row9 col0\" >High Cardinality Method </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row9_col1\" class=\"data row9 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row10_col0\" class=\"data row10 col0\" >Sampled Data</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row10_col1\" class=\"data row10 col1\" >(2536, 41)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row11_col1\" class=\"data row11 col1\" >(1775, 54)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row12_col1\" class=\"data row12 col1\" >(761, 54)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row13_col0\" class=\"data row13 col0\" >Numeric Imputer </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row13_col1\" class=\"data row13 col1\" >mean</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row14_col0\" class=\"data row14 col0\" >Categorical Imputer </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row14_col1\" class=\"data row14 col1\" >constant</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row15_col0\" class=\"data row15 col0\" >Normalize </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row15_col1\" class=\"data row15 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row16_col0\" class=\"data row16 col0\" >Normalize Method </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row16_col1\" class=\"data row16 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row17_col0\" class=\"data row17 col0\" >Transformation </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row17_col1\" class=\"data row17 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row18_col0\" class=\"data row18 col0\" >Transformation Method </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row18_col1\" class=\"data row18 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row19_col0\" class=\"data row19 col0\" >PCA </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row19_col1\" class=\"data row19 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row20_col0\" class=\"data row20 col0\" >PCA Method </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row20_col1\" class=\"data row20 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row21_col0\" class=\"data row21 col0\" >PCA Components </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row21_col1\" class=\"data row21 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row22_col0\" class=\"data row22 col0\" >Ignore Low Variance </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row22_col1\" class=\"data row22 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row23_col0\" class=\"data row23 col0\" >Combine Rare Levels </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row23_col1\" class=\"data row23 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row24_col0\" class=\"data row24 col0\" >Rare Level Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row24_col1\" class=\"data row24 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row25_col0\" class=\"data row25 col0\" >Numeric Binning </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row25_col1\" class=\"data row25 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row26_col0\" class=\"data row26 col0\" >Remove Outliers </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row26_col1\" class=\"data row26 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row27_col0\" class=\"data row27 col0\" >Outliers Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row27_col1\" class=\"data row27 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row28_col0\" class=\"data row28 col0\" >Remove Multicollinearity </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row28_col1\" class=\"data row28 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row29_col0\" class=\"data row29 col0\" >Multicollinearity Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row29_col1\" class=\"data row29 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row30_col0\" class=\"data row30 col0\" >Clustering </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row30_col1\" class=\"data row30 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row31_col0\" class=\"data row31 col0\" >Clustering Iteration </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row31_col1\" class=\"data row31 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row32_col0\" class=\"data row32 col0\" >Polynomial Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row32_col1\" class=\"data row32 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row33_col0\" class=\"data row33 col0\" >Polynomial Degree </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row33_col1\" class=\"data row33 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row34_col0\" class=\"data row34 col0\" >Trignometry Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row34_col1\" class=\"data row34 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row35_col0\" class=\"data row35 col0\" >Polynomial Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row35_col1\" class=\"data row35 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row36_col0\" class=\"data row36 col0\" >Group Features </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row36_col1\" class=\"data row36 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row37_col0\" class=\"data row37 col0\" >Feature Selection </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row37_col1\" class=\"data row37 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row38_col0\" class=\"data row38 col0\" >Features Selection Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row38_col1\" class=\"data row38 col1\" >None</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row39_col0\" class=\"data row39 col0\" >Feature Interaction </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row39_col1\" class=\"data row39 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row40_col0\" class=\"data row40 col0\" >Feature Ratio </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row40_col1\" class=\"data row40 col1\" >False</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row41_col0\" class=\"data row41 col0\" >Interaction Threshold </td>\n",
              "                        <td id=\"T_63522e90_c408_11ea_8ed5_0242ac1c0002row41_col1\" class=\"data row41 col1\" >None</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fe3457f89e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HapeY5ZuH17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "adee68c150bf489c889545687cbbc579",
            "ab1ebe96f6734ea8ac48d8f733a5e0f4",
            "0d1fbc4553ff4804b45074db0e1b49fa"
          ]
        },
        "outputId": "94a46509-b4fc-449e-9e84-3179799d574e"
      },
      "source": [
        "compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002 th {\n",
              "          text-align: left;\n",
              "    }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col2 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col1 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col3 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col5 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col6 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col1 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col2 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col3 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col5 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col6 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col1 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col2 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col3 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col4 {\n",
              "            background-color:  yellow;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col5 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col6 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col1 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col2 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col3 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col4 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col5 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col6 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col1 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col2 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col3 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col4 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col5 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col6 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col0 {\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col1 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col2 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col3 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col4 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col5 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }    #T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col6 {\n",
              "            : ;\n",
              "            text-align:  left;\n",
              "        }</style><table id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row0_col6\" class=\"data row0 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Naive Bayes</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col4\" class=\"data row1 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col5\" class=\"data row1 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col4\" class=\"data row2 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Ridge Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col5\" class=\"data row3 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row3_col6\" class=\"data row3 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col5\" class=\"data row4 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col1\" class=\"data row5 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col3\" class=\"data row5 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col4\" class=\"data row5 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row5_col6\" class=\"data row5 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Extra Trees Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col4\" class=\"data row6 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col5\" class=\"data row6 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col0\" class=\"data row7 col0\" >Extreme Gradient Boosting</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col4\" class=\"data row7 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col5\" class=\"data row7 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row7_col6\" class=\"data row7 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col0\" class=\"data row8 col0\" >Light Gradient Boosting Machine</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col1\" class=\"data row8 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col2\" class=\"data row8 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col3\" class=\"data row8 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col4\" class=\"data row8 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col5\" class=\"data row8 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row8_col6\" class=\"data row8 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col0\" class=\"data row9 col0\" >CatBoost Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col1\" class=\"data row9 col1\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col2\" class=\"data row9 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col3\" class=\"data row9 col3\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col4\" class=\"data row9 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col5\" class=\"data row9 col5\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row9_col6\" class=\"data row9 col6\" >1.000000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col0\" class=\"data row10 col0\" >Random Forest Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col1\" class=\"data row10 col1\" >0.999400</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col2\" class=\"data row10 col2\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col3\" class=\"data row10 col3\" >0.998500</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col4\" class=\"data row10 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col5\" class=\"data row10 col5\" >0.999200</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row10_col6\" class=\"data row10 col6\" >0.998800</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col1\" class=\"data row11 col1\" >0.999400</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col2\" class=\"data row11 col2\" >0.999300</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col3\" class=\"data row11 col3\" >0.998500</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col4\" class=\"data row11 col4\" >1.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col5\" class=\"data row11 col5\" >0.999200</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row11_col6\" class=\"data row11 col6\" >0.998800</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col1\" class=\"data row12 col1\" >0.868500</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col3\" class=\"data row12 col3\" >0.700000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col4\" class=\"data row12 col4\" >0.717700</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col5\" class=\"data row12 col5\" >0.682900</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row12_col6\" class=\"data row12 col6\" >0.664500</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col0\" class=\"data row13 col0\" >Linear Discriminant Analysis</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col1\" class=\"data row13 col1\" >0.814700</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col2\" class=\"data row13 col2\" >0.909600</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col3\" class=\"data row13 col3\" >0.908800</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col4\" class=\"data row13 col4\" >0.695500</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col5\" class=\"data row13 col5\" >0.787300</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row13_col6\" class=\"data row13 col6\" >0.628600</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col0\" class=\"data row14 col0\" >K Neighbors Classifier</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col1\" class=\"data row14 col1\" >0.680000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col2\" class=\"data row14 col2\" >0.736400</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col3\" class=\"data row14 col3\" >0.554000</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col4\" class=\"data row14 col4\" >0.578700</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col5\" class=\"data row14 col5\" >0.565600</td>\n",
              "                        <td id=\"T_7833e16e_c408_11ea_8ed5_0242ac1c0002row14_col6\" class=\"data row14 col6\" >0.312600</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fe3330b29b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjFDUsCJLKAr",
        "colab_type": "text"
      },
      "source": [
        "The highlighted models are capable of classifying the placed and unplaced students with 100% accuracy on 10 fold cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_mhdoFOoOsU",
        "colab_type": "text"
      },
      "source": [
        "#Converting notebook to PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6_9hxFizUta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2ee684f1-9376-479a-a482-5d28454c8358"
      },
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (1.19.2.4~dfsg-1build4).\n",
            "texlive is already the newest version (2017.20180305-1).\n",
            "texlive-latex-extra is already the newest version (2017.20180305-2).\n",
            "texlive-xetex is already the newest version (2017.20180305-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.6/dist-packages (1.5)\n",
            "Requirement already satisfied: pip>=8.1.0 in /usr/local/lib/python3.6/dist-packages (from pypandoc) (19.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pypandoc) (47.3.1)\n",
            "Requirement already satisfied: wheel>=0.25.0 in /usr/local/lib/python3.6/dist-packages (from pypandoc) (0.34.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0MNkTAdQidi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/Colab Notebooks/Pathrise Assignment.ipynb' '/content/drive/My Drive/Colab Notebooks/Pathrise Assignment/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImMuf79_TexR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d2b4fc6-c3cf-44d8-ec22-c6adff22522a"
      },
      "source": [
        "!jupyter nbconvert --to PDF 'Pathrise Assignment.ipynb'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook Pathrise Assignment.ipynb to PDF\n",
            "[NbConvertApp] Support files will be in Pathrise Assignment_files/\n",
            "[NbConvertApp] Making directory ./Pathrise Assignment_files\n",
            "[NbConvertApp] Making directory ./Pathrise Assignment_files\n",
            "[NbConvertApp] Making directory ./Pathrise Assignment_files\n",
            "[NbConvertApp] Writing 378152 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "[NbConvertApp] CRITICAL | xelatex failed: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "This is XeTeX, Version 3.14159265-2.6-0.99998 (TeX Live 2017/Debian) (preloaded format=xelatex)\n",
            " restricted \\write18 enabled.\n",
            "entering extended mode\n",
            "(./notebook.tex\n",
            "LaTeX2e <2017-04-15>\n",
            "Babel <3.18> and hyphenation patterns for 3 language(s) loaded.\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
            "Document Class: article 2014/09/29 v1.4h Standard LaTeX document class\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n",
            "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n",
            "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n",
            "f))))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n",
            "tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n",
            "tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",
            ".tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n",
            "ric.code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n",
            "e.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",
            ".code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n",
            "tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",
            ".tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n",
            "tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n",
            "thmetics.code.tex)))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n",
            "x)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n",
            "code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",
            ".tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n",
            "x)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n",
            "ode.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n",
            "s.code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",
            ")\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n",
            "ex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",
            ".code.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n",
            "x)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",
            ")\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n",
            "\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n",
            "tex))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n",
            "x)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n",
            "ode.tex)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n",
            "tex)))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",
            ") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",
            ")\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",
            ".sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",
            ".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n",
            "Library (tcolorbox): 'tcbbreakable.code.tex' version '4.12'\n",
            ")) (/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/t1enc.def)\n",
            "(/usr/share/texmf/tex/latex/lm/t1lmr.fd))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/mathpazo.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
            "For additional information on amsmath, use the `?' option.\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/inputenc.sty\n",
            "\n",
            "Package inputenc Warning: inputenc package ignored with utf8 based engines.\n",
            "\n",
            ") (/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n",
            "Style option: `fancyvrb' v2.7a, with DG/SPQR fixes, and firstline=lastline fix \n",
            "<2008/02/07> (tvz))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty))))\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n",
            "No file notebook.aux.\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/t1ppl.fd)\n",
            "ABD: EveryShipout initializing macros\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n",
            "*geometry* driver: auto-detecting\n",
            "*geometry* detected driver: xetex\n",
            "*geometry* verbose mode - [ preamble ] result:\n",
            "* driver: xetex\n",
            "* paper: <default>\n",
            "* layout: <same size as paper>\n",
            "* layoutoffset:(h,v)=(0.0pt,0.0pt)\n",
            "* modes: \n",
            "* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n",
            "* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n",
            "* \\paperwidth=614.295pt\n",
            "* \\paperheight=794.96999pt\n",
            "* \\textwidth=469.75502pt\n",
            "* \\textheight=650.43001pt\n",
            "* \\oddsidemargin=0.0pt\n",
            "* \\evensidemargin=0.0pt\n",
            "* \\topmargin=-37.0pt\n",
            "* \\headheight=12.0pt\n",
            "* \\headsep=25.0pt\n",
            "* \\topskip=11.0pt\n",
            "* \\footskip=30.0pt\n",
            "* \\marginparwidth=59.0pt\n",
            "* \\marginparsep=10.0pt\n",
            "* \\columnsep=10.0pt\n",
            "* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n",
            "* \\hoffset=0.0pt\n",
            "* \\voffset=0.0pt\n",
            "* \\mag=1000\n",
            "* \\@twocolumnfalse\n",
            "* \\@twosidefalse\n",
            "* \\@mparswitchfalse\n",
            "* \\@reversemarginfalse\n",
            "* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n",
            "\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n",
            "\n",
            "Package hyperref Warning: Rerun to get /PageLabels entry.\n",
            "\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/ot1ppl.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omlzplm.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omszplm.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omxzplm.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/psnfss/ot1zplm.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n",
            "\n",
            "LaTeX Warning: No \\author given.\n",
            "\n",
            "(/usr/share/texmf/tex/latex/lm/t1lmtt.fd)\n",
            "(/usr/share/texmf/tex/latex/lm/ts1lmtt.fd)\n",
            "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n",
            "[1] [2] [3] [4]\n",
            "! Missing $ inserted.\n",
            "<inserted text> \n",
            "                $\n",
            "l.637 ...nment_files/Pathrise Assignment_20_0.png}\n",
            "                                                  \n",
            "? \n",
            "! Emergency stop.\n",
            "<inserted text> \n",
            "                $\n",
            "l.637 ...nment_files/Pathrise Assignment_20_0.png}\n",
            "                                                  \n",
            "Output written on notebook.pdf (4 pages).\n",
            "Transcript written on notebook.log.\n",
            "\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 41161 bytes to Pathrise Assignment.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3nv4oilTo_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "384efd01-fd63-43d4-e21b-7d465b2ff8f8"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mcatboost_info\u001b[0m/      'Pathrise Assignment.ipynb'\n",
            " data_Pathrise.xlsx  'Pathrise Assignment.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}